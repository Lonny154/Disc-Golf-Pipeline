{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faf48672-facf-45fa-a62e-9e2f4b34d370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sdf = spark.read.format(\"delta\").load(uri + \"PDGA_project/Silver\")   # or Gold\n",
    "\n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6ce9a02-594b-4512-9549-acbc0aa56f6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sdf.select(F.avg(\"PRCP_3day_avg\"), F.max(\"PRCP_3day_avg\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1bd66d2-b05b-48c7-80dc-5fa8f937a3d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SIMPLE LINEAR REGRESSION: C1X_Putt_Pct ~ AWND_3day_avg + PRCP_3day_avg + TMAX_3day_avg\n",
    "# + PLOT: Predicted C1X_Putt_Pct vs Wind\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#  Ensure numeric types\n",
    "numeric_cols = [\"C1X_Putt_Pct\", \"AWND_3day_avg\", \"PRCP_3day_avg\", \"TMAX_3day_avg\"]\n",
    "for c in numeric_cols:\n",
    "    sdf = sdf.withColumn(c, F.col(c).cast(\"double\"))\n",
    "\n",
    "#  Drop rows with missing values in model columns\n",
    "sdf_simple = sdf.dropna(subset=numeric_cols)\n",
    "\n",
    "#  Assemble features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"AWND_3day_avg\", \"PRCP_3day_avg\", \"TMAX_3day_avg\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "sdf_assembled = assembler.transform(sdf_simple)\n",
    "\n",
    "#  Linear regression model\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"C1X_Putt_Pct\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "model = lr.fit(sdf_assembled)\n",
    "summary = model.summary\n",
    "\n",
    "print(\"=== Simple Linear Regression: C1X_Putt_Pct ~ AWND + PRCP + TMAX ===\")\n",
    "print(\"RMSE:\", summary.rootMeanSquaredError)\n",
    "print(\"R2:\", summary.r2)\n",
    "print(\"Coefficients (AWND, PRCP, TMAX):\", model.coefficients)\n",
    "print(\"Intercept:\", model.intercept)\n",
    "\n",
    "#  Build prediction grid: vary wind, hold PRCP & TMAX at their means\n",
    "stats = sdf_simple.agg(\n",
    "    F.min(\"AWND_3day_avg\").alias(\"min_wind\"),\n",
    "    F.max(\"AWND_3day_avg\").alias(\"max_wind\"),\n",
    "    F.avg(\"PRCP_3day_avg\").alias(\"mean_prcp\"),\n",
    "    F.avg(\"TMAX_3day_avg\").alias(\"mean_tmax\")\n",
    ").collect()[0]\n",
    "\n",
    "min_wind = float(stats[\"min_wind\"])\n",
    "max_wind = float(stats[\"max_wind\"])\n",
    "mean_prcp = float(stats[\"mean_prcp\"])\n",
    "mean_tmax = float(stats[\"mean_tmax\"])\n",
    "\n",
    "# Create a range of wind values\n",
    "wind_vals = np.linspace(min_wind, max_wind, 50)\n",
    "\n",
    "# Spark DataFrame for prediction grid\n",
    "pred_input_rows = [(float(w), mean_prcp, mean_tmax) for w in wind_vals]\n",
    "pred_input = spark.createDataFrame(\n",
    "    pred_input_rows,\n",
    "    [\"AWND_3day_avg\", \"PRCP_3day_avg\", \"TMAX_3day_avg\"]\n",
    ")\n",
    "\n",
    "pred_features = assembler.transform(pred_input)\n",
    "predicted = model.transform(pred_features).select(\n",
    "    \"AWND_3day_avg\", \"prediction\"\n",
    ").orderBy(\"AWND_3day_avg\").toPandas()\n",
    "\n",
    "#  Plot: Predicted C1X putting vs Wind\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(predicted[\"AWND_3day_avg\"], predicted[\"prediction\"])\n",
    "plt.xlabel(\"Average Wind Speed (AWND_3day_avg)\")\n",
    "plt.ylabel(\"Predicted C1X Putting %\")\n",
    "plt.title(\"Predicted C1X_Putt_Pct vs Wind\\n(PRCP & TMAX held at their mean values)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4b36e3e-55af-4a73-a25e-05b28f697128",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# BETTER SIMPLE MODEL:\n",
    "# Convert PRCP → mm (NOAA = tenths of mm)\n",
    "# Fit Linear Regression: C1X_Putt_Pct ~ AWND + PRCP_mm + TMAX\n",
    "# Plot predicted C1X vs Wind\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "\n",
    "# 1. Load CSV\n",
    "\n",
    "\n",
    "\n",
    "# 2. Ensure correct numeric types\n",
    "\n",
    "numeric_cols = [\"C1X_Putt_Pct\", \"AWND_3day_avg\", \"PRCP_3day_avg\", \"TMAX_3day_avg\"]\n",
    "for c in numeric_cols:\n",
    "    sdf = sdf.withColumn(c, F.col(c).cast(\"double\"))\n",
    "\n",
    "\n",
    "# 3. FIX PRECIPITATION UNITS\n",
    "# NOAA PRCP = tenths of mm → convert to mm\n",
    "\n",
    "sdf = sdf.withColumn(\"PRCP_mm\", F.col(\"PRCP_3day_avg\") / 10.0)\n",
    "\n",
    "\n",
    "# 4. Drop rows with missing values\n",
    "\n",
    "sdf_simple = sdf.dropna(subset=[\"C1X_Putt_Pct\", \"AWND_3day_avg\", \"PRCP_mm\", \"TMAX_3day_avg\"])\n",
    "\n",
    "\n",
    "# 5. Build Feature Vector\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"AWND_3day_avg\", \"PRCP_mm\", \"TMAX_3day_avg\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "sdf_assembled = assembler.transform(sdf_simple)\n",
    "\n",
    "\n",
    "# 6. Fit Linear Regression Model\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"C1X_Putt_Pct\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "model = lr.fit(sdf_assembled)\n",
    "summary = model.summary\n",
    "\n",
    "print(\"=== Improved Linear Regression: C1X_Putt_Pct ~ AWND + PRCP_mm + TMAX ===\")\n",
    "print(\"RMSE:\", summary.rootMeanSquaredError)\n",
    "print(\"R2:\", summary.r2)\n",
    "print(\"Coefficients (AWND, PRCP_mm, TMAX):\", model.coefficients)\n",
    "print(\"Intercept:\", model.intercept)\n",
    "\n",
    "\n",
    "# 7. Create prediction grid\n",
    "\n",
    "stats = sdf_simple.agg(\n",
    "    F.min(\"AWND_3day_avg\").alias(\"min_wind\"),\n",
    "    F.max(\"AWND_3day_avg\").alias(\"max_wind\"),\n",
    "    F.avg(\"PRCP_mm\").alias(\"mean_prcp\"),\n",
    "    F.avg(\"TMAX_3day_avg\").alias(\"mean_tmax\")\n",
    ").collect()[0]\n",
    "\n",
    "min_wind = float(stats[\"min_wind\"])\n",
    "max_wind = float(stats[\"max_wind\"])\n",
    "mean_prcp = float(stats[\"mean_prcp\"])\n",
    "mean_tmax = float(stats[\"mean_tmax\"])\n",
    "\n",
    "wind_vals = np.linspace(min_wind, max_wind, 50)\n",
    "rows = [(float(w), mean_prcp, mean_tmax) for w in wind_vals]\n",
    "\n",
    "pred_input = spark.createDataFrame(\n",
    "    rows, [\"AWND_3day_avg\", \"PRCP_mm\", \"TMAX_3day_avg\"]\n",
    ")\n",
    "\n",
    "pred_feat = assembler.transform(pred_input)\n",
    "predicted = (\n",
    "    model.transform(pred_feat)\n",
    "         .select(\"AWND_3day_avg\", \"prediction\")\n",
    "         .orderBy(\"AWND_3day_avg\")\n",
    "         .toPandas()\n",
    ")\n",
    "\n",
    "\n",
    "# 8. Plot: Predicted C1X vs Wind\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(predicted[\"AWND_3day_avg\"], predicted[\"prediction\"], linewidth=2)\n",
    "plt.xlabel(\"Average Wind Speed (mph)\")\n",
    "plt.ylabel(\"Predicted C1X Putting %\")\n",
    "plt.title(\"Predicted C1X_Putt_Pct vs Wind\\n(PRCP & TMAX held at their mean values)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4aa7998-1ab2-47fb-9cf8-d26a1b29b2b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CORRECT SKILL-AWARE MODEL:\n",
    "#  - Compute avg_rating per player\n",
    "#  - Convert PRCP -> mm\n",
    "#  - Linear Regression: C1X ~ AWND + PRCP_mm + TMAX + avg_rating\n",
    "#  - Plot predicted C1X vs Wind\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1. Ensure numeric types\n",
    "\n",
    "sdf = sdf.withColumn(\"evt_rating\", F.col(\"evt_rating\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"C1X_Putt_Pct\", F.col(\"C1X_Putt_Pct\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"AWND_3day_avg\", F.col(\"AWND_3day_avg\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"PRCP_3day_avg\", F.col(\"PRCP_3day_avg\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"TMAX_3day_avg\", F.col(\"TMAX_3day_avg\").cast(\"double\"))\n",
    "\n",
    "\n",
    "# 2. Compute player skill (avg_rating)\n",
    "\n",
    "player_skill = (\n",
    "    sdf.groupBy(\"player_name\")\n",
    "       .agg(F.avg(\"evt_rating\").alias(\"avg_rating\"))\n",
    ")\n",
    "\n",
    "sdf2 = sdf.join(player_skill, \"player_name\", \"left\")\n",
    "\n",
    "\n",
    "# 3. Fix PRCP units\n",
    "\n",
    "sdf2 = sdf2.withColumn(\"PRCP_mm\", F.col(\"PRCP_3day_avg\") / 10.0)\n",
    "\n",
    "\n",
    "# 4. Drop missing rows\n",
    "\n",
    "model_cols = [\"C1X_Putt_Pct\", \"AWND_3day_avg\", \"PRCP_mm\", \"TMAX_3day_avg\", \"avg_rating\"]\n",
    "sdf_model = sdf2.dropna(subset=model_cols)\n",
    "\n",
    "\n",
    "# 5. Assemble feature vector (INCLUDING SKILL)\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"AWND_3day_avg\", \"PRCP_mm\", \"TMAX_3day_avg\", \"avg_rating\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "sdf_assembled = assembler.transform(sdf_model)\n",
    "\n",
    "\n",
    "# 6. Fit Linear Regression\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"C1X_Putt_Pct\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "model = lr.fit(sdf_assembled)\n",
    "summary = model.summary\n",
    "\n",
    "print(\"=== TRUE Skill-Aware Regression ===\")\n",
    "print(\"RMSE:\", summary.rootMeanSquaredError)\n",
    "print(\"R2:\", summary.r2)\n",
    "print(\"Coefficients (AWND, PRCP_mm, TMAX, avg_rating):\", model.coefficients)\n",
    "print(\"Intercept:\", model.intercept)\n",
    "\n",
    "\n",
    "# 7. Build prediction curve vs wind\n",
    "\n",
    "stats = sdf_model.agg(\n",
    "    F.min(\"AWND_3day_avg\").alias(\"min_wind\"),\n",
    "    F.max(\"AWND_3day_avg\").alias(\"max_wind\"),\n",
    "    F.avg(\"PRCP_mm\").alias(\"mean_prcp\"),\n",
    "    F.avg(\"TMAX_3day_avg\").alias(\"mean_tmax\"),\n",
    "    F.avg(\"avg_rating\").alias(\"mean_rating\")\n",
    ").collect()[0]\n",
    "\n",
    "wind_vals = np.linspace(float(stats[\"min_wind\"]), float(stats[\"max_wind\"]), 50)\n",
    "\n",
    "rows = [(float(w), float(stats[\"mean_prcp\"]), float(stats[\"mean_tmax\"]), float(stats[\"mean_rating\"]))\n",
    "        for w in wind_vals]\n",
    "\n",
    "pred_input = spark.createDataFrame(\n",
    "    rows,\n",
    "    [\"AWND_3day_avg\", \"PRCP_mm\", \"TMAX_3day_avg\", \"avg_rating\"]\n",
    ")\n",
    "\n",
    "pred_feat = assembler.transform(pred_input)\n",
    "predicted = (\n",
    "    model.transform(pred_feat)\n",
    "         .select(\"AWND_3day_avg\", \"prediction\")\n",
    "         .orderBy(\"AWND_3day_avg\")\n",
    "         .toPandas()\n",
    ")\n",
    "\n",
    "\n",
    "# 8. Plot predicted C1X vs wind\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(predicted[\"AWND_3day_avg\"], predicted[\"prediction\"], linewidth=2)\n",
    "plt.xlabel(\"Average Wind (mph)\")\n",
    "plt.ylabel(\"Predicted C1X Putting %\")\n",
    "plt.title(\"Predicted C1X Putting vs Wind\\n(PRCP, TMAX, and Skill Held Constant)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ad33132-7694-444c-8da1-a97dea6faa7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# WIND × SKILL INTERACTION MODEL\n",
    "# C1X_Putt_Pct ~ AWND + PRCP_mm + TMAX + avg_rating + (AWND * avg_rating)\n",
    "# Produces two prediction lines: low-skill vs high-skill players\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1. Ensure numeric types\n",
    "\n",
    "sdf = sdf.withColumn(\"evt_rating\", F.col(\"evt_rating\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"C1X_Putt_Pct\", F.col(\"C1X_Putt_Pct\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"AWND_3day_avg\", F.col(\"AWND_3day_avg\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"PRCP_3day_avg\", F.col(\"PRCP_3day_avg\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"TMAX_3day_avg\", F.col(\"TMAX_3day_avg\").cast(\"double\"))\n",
    "\n",
    "\n",
    "# 2. Compute player skill: avg_rating\n",
    "\n",
    "player_skill = (\n",
    "    sdf.groupBy(\"player_name\")\n",
    "       .agg(F.avg(\"evt_rating\").alias(\"avg_rating\"))\n",
    ")\n",
    "\n",
    "sdf2 = sdf.join(player_skill, \"player_name\", \"left\")\n",
    "\n",
    "\n",
    "# 3. Fix PRCP units (tenths mm → mm)\n",
    "\n",
    "sdf2 = sdf2.withColumn(\"PRCP_mm\", F.col(\"PRCP_3day_avg\") / 10.0)\n",
    "\n",
    "\n",
    "# 4. Create Interaction Term: AWND × avg_rating\n",
    "\n",
    "sdf2 = sdf2.withColumn(\"AWND_x_skill\", F.col(\"AWND_3day_avg\") * F.col(\"avg_rating\"))\n",
    "sdf2 = sdf2.withColumn(\"AWND_x_skill\", (F.col(\"AWND_3day_avg\") * F.col(\"avg_rating\")).cast(\"double\"))\n",
    "\n",
    "\n",
    "# 5. Drop missing rows\n",
    "\n",
    "model_cols = [\n",
    "    \"C1X_Putt_Pct\", \"AWND_3day_avg\", \"PRCP_mm\",\n",
    "    \"TMAX_3day_avg\", \"avg_rating\", \"AWND_x_skill\"\n",
    "]\n",
    "\n",
    "sdf_model = sdf2.dropna(subset=model_cols)\n",
    "\n",
    "\n",
    "# 6. Assemble features\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"AWND_3day_avg\", \"PRCP_mm\", \"TMAX_3day_avg\",\n",
    "        \"avg_rating\", \"AWND_x_skill\"\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "sdf_assembled = assembler.transform(sdf_model)\n",
    "\n",
    "\n",
    "# 7. Fit Linear Regression\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"C1X_Putt_Pct\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "model = lr.fit(sdf_assembled)\n",
    "summary = model.summary\n",
    "\n",
    "print(\"=== WIND × SKILL INTERACTION MODEL ===\")\n",
    "print(\"RMSE:\", summary.rootMeanSquaredError)\n",
    "print(\"R2:\", summary.r2)\n",
    "print(\"\\nCoefficients:\")\n",
    "print(\" AWND:\", model.coefficients[0])\n",
    "print(\" PRCP_mm:\", model.coefficients[1])\n",
    "print(\" TMAX:\", model.coefficients[2])\n",
    "print(\" avg_rating:\", model.coefficients[3])\n",
    "print(\" AWND_x_skill:\", model.coefficients[4])\n",
    "print(\"Intercept:\", model.intercept)\n",
    "\n",
    "\n",
    "# 8. Prediction curves for LOW vs HIGH skill\n",
    "\n",
    "stats = sdf_model.agg(\n",
    "    F.min(\"AWND_3day_avg\").alias(\"min_wind\"),\n",
    "    F.max(\"AWND_3day_avg\").alias(\"max_wind\"),\n",
    "    F.avg(\"PRCP_mm\").alias(\"mean_prcp\"),\n",
    "    F.avg(\"TMAX_3day_avg\").alias(\"mean_tmax\"),\n",
    "    F.percentile_approx(\"avg_rating\", 0.1).alias(\"low_skill\"),\n",
    "    F.percentile_approx(\"avg_rating\", 0.9).alias(\"high_skill\")\n",
    ").collect()[0]\n",
    "\n",
    "min_wind = float(stats[\"min_wind\"])\n",
    "max_wind = float(stats[\"max_wind\"])\n",
    "mean_prcp = float(stats[\"mean_prcp\"])\n",
    "mean_tmax = float(stats[\"mean_tmax\"])\n",
    "low_skill = float(stats[\"low_skill\"])\n",
    "high_skill = float(stats[\"high_skill\"])\n",
    "\n",
    "wind_vals = np.linspace(min_wind, max_wind, 60)\n",
    "\n",
    "# Build prediction rows\n",
    "rows_low = [(float(w), mean_prcp, mean_tmax, low_skill, w * low_skill)\n",
    "            for w in wind_vals]\n",
    "\n",
    "rows_high = [(float(w), mean_prcp, mean_tmax, high_skill, w * high_skill)\n",
    "             for w in wind_vals]\n",
    "\n",
    "# Create DataFrames\n",
    "pred_low = spark.createDataFrame(rows_low,\n",
    "    [\"AWND_3day_avg\", \"PRCP_mm\", \"TMAX_3day_avg\", \"avg_rating\", \"AWND_x_skill\"])\n",
    "pred_high = spark.createDataFrame(rows_high,\n",
    "    [\"AWND_3day_avg\", \"PRCP_mm\", \"TMAX_3day_avg\", \"avg_rating\", \"AWND_x_skill\"])\n",
    "\n",
    "pred_low = model.transform(assembler.transform(pred_low)).toPandas()\n",
    "pred_high = model.transform(assembler.transform(pred_high)).toPandas()\n",
    "\n",
    "\n",
    "# 9. Plot LOW vs HIGH skill curves\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(pred_low[\"AWND_3day_avg\"], pred_low[\"prediction\"],\n",
    "         label=\"Low Skill Player\", linewidth=2)\n",
    "plt.plot(pred_high[\"AWND_3day_avg\"], pred_high[\"prediction\"],\n",
    "         label=\"High Skill Player\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Average Wind Speed (mph)\")\n",
    "plt.ylabel(\"Predicted C1X Putting %\")\n",
    "plt.title(\"Wind × Skill Interaction Effect on C1X Putting\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0a1bd62-751b-45b8-8ea4-b7f7d511d009",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# EVENT FIXED EFFECTS MODEL\n",
    "# C1X ~ AWND + PRCP_mm + TMAX + avg_rating + (AWND * avg_rating) + event fixed effects\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1. Ensure numeric columns\n",
    "\n",
    "sdf = sdf.withColumn(\"evt_rating\", F.col(\"evt_rating\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"C1X_Putt_Pct\", F.col(\"C1X_Putt_Pct\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"AWND_3day_avg\", F.col(\"AWND_3day_avg\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"PRCP_3day_avg\", F.col(\"PRCP_3day_avg\").cast(\"double\"))\n",
    "sdf = sdf.withColumn(\"TMAX_3day_avg\", F.col(\"TMAX_3day_avg\").cast(\"double\"))\n",
    "\n",
    "\n",
    "# 2. Compute avg_rating per player\n",
    "\n",
    "player_skill = (\n",
    "    sdf.groupBy(\"player_name\")\n",
    "       .agg(F.avg(\"evt_rating\").alias(\"avg_rating\"))\n",
    ")\n",
    "\n",
    "sdf2 = sdf.join(player_skill, \"player_name\", \"left\")\n",
    "\n",
    "\n",
    "# 3. Fix PRCP units\n",
    "\n",
    "sdf2 = sdf2.withColumn(\"PRCP_mm\", (F.col(\"PRCP_3day_avg\") / 10.0).cast(\"double\"))\n",
    "\n",
    "\n",
    "# 4. Create interaction term: wind × skill\n",
    "\n",
    "sdf2 = sdf2.withColumn(\"AWND_x_skill\",\n",
    "                       (F.col(\"AWND_3day_avg\") * F.col(\"avg_rating\")).cast(\"double\"))\n",
    "\n",
    "\n",
    "# 5. Drop rows missing relevant columns\n",
    "\n",
    "model_cols = [\n",
    "    \"C1X_Putt_Pct\", \"AWND_3day_avg\", \"PRCP_mm\",\n",
    "    \"TMAX_3day_avg\", \"avg_rating\", \"AWND_x_skill\", \"pdga_event_id\"\n",
    "]\n",
    "sdf_model = sdf2.dropna(subset=model_cols)\n",
    "\n",
    "\n",
    "# 6. Add EVENT FIXED EFFECTS\n",
    "\n",
    "# Convert event_id to index\n",
    "event_indexer = StringIndexer(\n",
    "    inputCol=\"pdga_event_id\",\n",
    "    outputCol=\"event_idx\",\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "# One-hot encode event index -> event vector\n",
    "event_encoder = OneHotEncoder(\n",
    "    inputCols=[\"event_idx\"],\n",
    "    outputCols=[\"event_vec\"],\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "\n",
    "# 7. Assemble features (weather + skill + interaction + event FE)\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"AWND_3day_avg\", \"PRCP_mm\", \"TMAX_3day_avg\",\n",
    "        \"avg_rating\", \"AWND_x_skill\", \"event_vec\"\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "\n",
    "# 8. Linear Regression model\n",
    "\n",
    "lr = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"C1X_Putt_Pct\",\n",
    "    predictionCol=\"prediction\",\n",
    "    maxIter=100\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[event_indexer, event_encoder, assembler, lr])\n",
    "\n",
    "# Fit model\n",
    "model = pipeline.fit(sdf_model)\n",
    "lr_model = model.stages[-1]\n",
    "summary = lr_model.summary\n",
    "\n",
    "\n",
    "# 9. Print results\n",
    "\n",
    "print(\"=== EVENT FIXED EFFECTS MODEL ===\")\n",
    "print(\"RMSE:\", summary.rootMeanSquaredError)\n",
    "print(\"R2:\", summary.r2)\n",
    "\n",
    "print(\"\\nCoefficients:\")\n",
    "print(\" AWND:\", lr_model.coefficients[0])\n",
    "print(\" PRCP_mm:\", lr_model.coefficients[1])\n",
    "print(\" TMAX:\", lr_model.coefficients[2])\n",
    "print(\" avg_rating:\", lr_model.coefficients[3])\n",
    "print(\" AWND_x_skill:\", lr_model.coefficients[4])\n",
    "\n",
    "print(\"\\nNumber of Event Fixed Effects:\", len(lr_model.coefficients) - 5)\n",
    "print(\"Intercept:\", lr_model.intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a941dad6-39b4-44bb-bf93-af604081e067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "serving = (sdf_model\n",
    "  .select(\"pdga_event_id\",\"player_name\",\"event_date\",\n",
    "          \"C1X_Putt_Pct\",\"AWND_3day_avg\",\"PRCP_mm\",\"TMAX_3day_avg\",\"avg_rating\",\"AWND_x_skill\"))\n",
    "\n",
    "serving.write.mode(\"overwrite\").format(\"delta\").save(uri + \"PDGA_project/Gold\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Serving Model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
